import os
import sys
import streamlit as st
import pandas as pd
import duckdb
from datetime import datetime
from src.Test_red.app_backend.data_utils import clean_numeric_data, detect_column_types
from src.Test_red.app_backend.analysis_utils import generate_data_summary, analyze_marketing_question, polish_with_gemini
from src.Test_red.app_backend.viz_utils import create_dynamic_visualizations
from src.Test_red.app_backend.sql_utils import generate_sql_query


def setup_dynamic_db() -> duckdb.DuckDBPyConnection:
    return duckdb.connect(database=':memory:')


def main():
    st.set_page_config(page_title="Dynamic Marketing Data Analyzer", page_icon="ğŸ“Š", layout="wide")
    st.title("ğŸš€ Dynamic Marketing Data Analyzer")
    st.markdown("### AI-Powered Analysis with Together AI + Gemini Integration")
    st.markdown("""
    **Workflow:**
    1. ğŸ“¤ Upload any marketing dataset (CSV/Excel)
    2. ğŸ” AI automatically analyzes columns and data structure
    3. ğŸ“Š Get comprehensive data summary and insights
    4. â“ Ask specific questions about your data
    5. ğŸ§  Together AI performs deep analysis
    6. âœ¨ Gemini polishes results into executive reports
    """)

    conn = setup_dynamic_db()
    st.markdown("---")
    uploaded_file = st.file_uploader("ğŸ“ Upload your marketing dataset", type=['csv', 'xlsx', 'xls'])

    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            df.columns = df.columns.str.strip()
            df = clean_numeric_data(df)
            for col in df.columns:
                if 'date' in col.lower() or 'time' in col.lower():
                    try:
                        df[col] = pd.to_datetime(df[col], errors='ignore')
                    except:
                        pass
            conn.register('marketing_data', df)
            st.success(f"âœ… Successfully loaded: {len(df):,} rows Ã— {len(df.columns)} columns")
            
            with st.spinner("ğŸ” Analyzing data structure..."):
                column_analysis = detect_column_types(df)

            with st.sidebar:
                st.header("ğŸ“Š Data Analysis")
                with st.expander("ğŸ“‹ Dataset Overview", expanded=True):
                    st.metric("Rows", f"{len(df):,}")
                    st.metric("Columns", len(df.columns))
                    total_nulls = df.isnull().sum().sum()
                    quality_score = max(0, 100 - (total_nulls / (len(df) * len(df.columns)) * 100))
                    st.metric("Data Quality", f"{quality_score:.1f}%")
                with st.expander("ğŸ” Column Analysis"):
                    purpose_counts = {}
                    for info in column_analysis.values():
                        purpose = info['likely_purpose']
                        purpose_counts[purpose] = purpose_counts.get(purpose, 0) + 1
                    st.write("**Column Types Detected:**")
                    for purpose, count in purpose_counts.items():
                        emoji = {
                            'temporal': 'ğŸ“…',
                            'financial': 'ğŸ’°',
                            'performance_metric': 'ğŸ“ˆ',
                            'volume_metric': 'ğŸ“Š',
                            'categorical': 'ğŸ·ï¸',
                            'numeric': 'ğŸ”¢',
                            'unknown': 'â“'
                        }.get(purpose, 'â“')
                        st.write(f"{emoji} {purpose.replace('_', ' ').title()}: {count}")
                with st.expander("ğŸ“ Column Details"):
                    for col, info in column_analysis.items():
                        st.write(f"**{col}**")
                        st.write(f"- Type: {info['likely_purpose']}")
                        st.write(f"- Data Type: {info['dtype']}")
                        st.write(f"- Missing: {info['null_count']} ({info['null_percentage']:.1f}%)")
                        st.write(f"- Unique: {info['unique_count']}")
                        if info.get('mean') is not None:
                            st.write(f"- Mean: {info['mean']:.2f}")
                        st.write("---")

            col1, col2 = st.columns([2, 1])
            with col1:
                with st.expander("ğŸ‘€ Data Preview", expanded=False):
                    st.dataframe(df.head(20), use_container_width=True)
                with st.expander("ğŸ“‹ AI Data Summary", expanded=True):
                    with st.spinner("ğŸ“ Generating AI data summary..."):
                        summary = generate_data_summary(df, column_analysis)
                    st.markdown(summary)
                with st.expander("ğŸ“Š Automatic Visualizations", expanded=False):
                    with st.spinner("ğŸ“ˆ Creating visualizations..."):
                        figures = create_dynamic_visualizations(df, column_analysis)
                    if figures:
                        for i, fig in enumerate(figures):
                            st.plotly_chart(fig, use_container_width=True, key=f"chart_{i}")
                    else:
                        st.info("No suitable visualizations could be generated automatically.")

            with col2:
                st.subheader("ğŸ’¡ Smart Insights")
                numeric_cols = [col for col, info in column_analysis.items() 
                                if info['likely_purpose'] in ['financial', 'performance_metric', 'volume_metric']]
                if numeric_cols:
                    for col in numeric_cols[:4]:
                        try:
                            if pd.api.types.is_numeric_dtype(df[col]):
                                value = df[col].sum() if 'spend' in col.lower() or 'cost' in col.lower() or 'sales' in col.lower() else df[col].mean()
                                st.metric(col, f"{value:,.2f}")
                        except:
                            pass
                st.markdown("**Data Quality:**")
                missing_cols = [col for col, info in column_analysis.items() if info['null_percentage'] > 5]
                if missing_cols:
                    st.warning(f"âš ï¸ {len(missing_cols)} columns with >5% missing data")
                else:
                    st.success("âœ… Good data completeness")

            st.markdown("---")
            st.subheader("ğŸ¤– Ask Questions About Your Data")
            suggested_questions = []
            if any(info['likely_purpose'] == 'financial' for info in column_analysis.values()):
                suggested_questions.extend([
                    "What are the spending trends over time?",
                    "Which periods had the highest ROI?",
                    "How do different channels compare in performance?"
                ])
            if any(info['likely_purpose'] == 'performance_metric' for info in column_analysis.values()):
                suggested_questions.extend([
                    "What factors drive performance variations?",
                    "Are there seasonal patterns in the metrics?",
                    "Which metrics are most correlated?"
                ])
            if suggested_questions:
                st.markdown("**ğŸ’¡ Suggested Questions:**")
                cols = st.columns(len(suggested_questions))
                for i, question in enumerate(suggested_questions):
                    if cols[i].button(question, key=f"suggest_{i}"):
                        st.session_state.user_question = question
            user_question = st.text_input(
                "Enter your question:",
                value=getattr(st.session_state, 'user_question', ''),
                placeholder="e.g., 'Why did performance drop in March?' or 'What's driving the ROI variations?'"
            )
            if user_question:
                st.markdown("---")
                col1, col2 = st.columns([3, 1])
                with col1:
                    with st.spinner("ğŸ§  Analyzing with Together AI..."):
                        together_analysis = analyze_marketing_question(df, user_question, column_analysis, summary)
                    st.subheader("ğŸ” Detailed Analysis (Together AI)")
                    with st.expander("View Technical Analysis", expanded=True):
                        st.markdown(together_analysis)
                    with st.spinner("âœ¨ Polishing with Gemini..."):
                        final_report = polish_with_gemini(user_question, together_analysis, summary)
                    st.subheader("ğŸ“Š Executive Report (Gemini)")
                    st.markdown(final_report)
                    with st.expander("ğŸ”§ SQL Query (Advanced)"):
                        try:
                            # 1) Ask Together to build the SQL query
                            sql_candidate = generate_sql_query(user_question, df, column_analysis)

                            # 2) If Together failed, generate_sql_query returns a string beginning with "Error"
                            #    (or otherwise is clearly not valid SQL). We check for that:
                            if not sql_candidate or sql_candidate.strip().lower().startswith("error"):
                                # Show a friendly error message instead of raw SQL
                                st.error("âŒ Could not generate a valid SQL query from Together AI.")
                            else:
                                # It looks like a real SQL statementâ€”display it and offer to execute it
                                st.code(sql_candidate, language='sql')

                                if st.button("Execute SQL"):
                                    try:
                                        # Run the SQL against DuckDB
                                        result_df = conn.execute(sql_candidate).df()
                                        st.dataframe(result_df, use_container_width=True)
                                    except Exception as e:
                                        st.error(f"SQL execution error: {e}")

                        except Exception as e:
                            # Any unexpected exception in generate_sql_query()
                            st.warning(f"Could not generate SQL: {e}")

                with col2:
                    st.info("ğŸ’¡ **Analysis Pipeline:**\n\n1. âœ… Data Structure Detection\n2. âœ… Together AI Analysis\n3. âœ… Gemini Report Polish\n4. ğŸ“Š Visual Insights")
        except Exception as e:
            st.error(f"Error processing file: {e}")
    else:
        st.info("ğŸ“¤ Upload your marketing dataset to begin AI-powered analysis")
        st.markdown("### ğŸ“‹ Supported Data Formats")
        st.markdown("""
        The AI automatically detects and analyzes:
        - **ğŸ“… Date/Time columns** - for trend analysis
        - **ğŸ’° Financial metrics** - spend, revenue, cost, sales
        - **ğŸ“ˆ Performance metrics** - ROI, ROAS, CTR, conversion rates
        - **ğŸ“Š Volume metrics** - clicks, impressions, leads
        - **ğŸ·ï¸ Categorical data** - campaigns, channels, sources
        
        Just upload your CSV or Excel file - no formatting required!
        """)

if __name__ == "__main__":
    main()