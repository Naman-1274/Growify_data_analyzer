import streamlit as st
import pandas as pd
import numpy as np
import tempfile
import os
import re
from dotenv import load_dotenv

from src.Test_red.app_backend.ingest import load_csv_file
from src.Test_red.app_backend.insight_engine import generate_code_from_gemini, generate_response
from src.Test_red.app_backend.code_executor import execute_code_snippet, CodeExecutionError
from src.Test_red.utils import df_to_markdown_full, get_column_summaries
from src.Test_red.exception import ModelAPIError, DataIngestionError

# -----------------------------
# 1) Load environment variables
# -----------------------------
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("âŒ Gemini API key missing. Add it to your .env file as GEMINI_API_KEY.")
    st.stop()

# -----------------------------
# 2) Streamlit page config
# -----------------------------
st.set_page_config(page_title="ðŸ“Š Chat with Your Dataset (Enhanced)", layout="wide")
st.title("ðŸ“Š Chat with Your Dataset (Gemini + Advanced Summary)")

# -----------------------------
# 3) Sidebar file uploader
# -----------------------------
st.sidebar.header("Upload a file (CSV/Excel)")
uploaded = st.sidebar.file_uploader("Choose a dataset", type=["csv", "xlsx", "xls"])

# -----------------------------
# 4) Initialize session_state
# -----------------------------
for key, default in [
    ("messages", []),
    ("memory_log", []),
    ("last_question", None)
]:
    if key not in st.session_state:
        st.session_state[key] = default

# ------------------------------------
# 5) Define the enhanced validation
# ------------------------------------
# A small set of English stopwords. Expand as needed.
STOPWORDS = {
    "the", "is", "in", "at", "of", "for", "to", "a", "an",
    "and", "or", "but", "if", "what", "which", "on", "by",
    "with", "as", "that", "this", "these", "those", "from",
    "be", "been", "are", "was", "were", "how", "when", "where",
    "why", "who", "whom", "can", "could", "should", "would",
    "do", "does", "did", "my", "your", "our", "their", "its"
}

def is_question_valid(text: str, df: pd.DataFrame) -> bool:
    """
    Returns False if the question is too short, too generic, or doesn't mention any column name.
    1) Require at least two non-empty tokens.
    2) Require at least one alphabetic character.
    3) Strip punctuation, lowercase, remove stopwords, and check if any remaining token matches a column name.
    """
    # 1) Tokenize and require â‰¥ 2 tokens
    tokens = [t for t in re.split(r"\s+", text.strip()) if t]
    if len(tokens) < 2:
        return False

    # 2) Must have at least one letter (reject â€œ1234â€)
    if not any(c.isalpha() for c in text):
        return False

    # 3) Normalize tokens: lowercase & strip leading/trailing punctuation
    normalized = []
    for t in tokens:
        w = t.lower().strip(".,!?\"'():;")
        if w:
            normalized.append(w)

    if not normalized:
        return False

    # 4) Remove stopwords
    meaningful = [w for w in normalized if w not in STOPWORDS]
    if len(meaningful) < 1:
        return False

    # 5) Check if any meaningful token matches a column name (substring match)
    lower_columns = [col.lower() for col in df.columns]
    for w in meaningful:
        for col in lower_columns:
            if w in col or col in w:
                return True

    # If no match was found, reject
    return False

# ---------------------------------------
# 6) Main logic: only run if â€˜uploadedâ€™ exists
# ---------------------------------------
if uploaded is not None:
    try:
        # 6.1) Save uploaded file to a temp path
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded.name)[1]) as tmp:
            tmp.write(uploaded.read())
            tmp_path = tmp.name

        # 6.2) Load DataFrame
        df = load_csv_file(tmp_path)
        st.success("âœ… Data loaded into a DataFrame!")

        # 6.3) Show a preview of the DataFrame
        with st.expander("ðŸ“„ Preview DataFrame"):
            st.dataframe(df.head(15), use_container_width=True)

        # 6.4) Ask the user for a question
        question = st.text_input("Ask a question about your dataset:")

        if question:
            # 6.4a) Early sanity check for illogical questions
            if not is_question_valid(question, df):
                st.warning(
                    "â— Your question seems too short, too generic, or doesnâ€™t reference any column.  \n"
                    "Please ask something more specificâ€”e.g.:  \n"
                    "â€¢ â€œTotal Sales (INR) by Region in Q1 2025â€  \n"
                    "â€¢ â€œAverage Units Sold by Product Categoryâ€  \n"
                    "â€¢ â€œTrend of Ads Spends (INR) over timeâ€"
                )
                st.stop()

            # 6.4b) Initialize summary & recommendation so they never cause NameError
            summary = None
            recommendation = None

            # 6.5) Build context for Gemini: column summaries & sample snippet
            snippet = df_to_markdown_full(df)
            summaries = get_column_summaries(df)
            history = [(item["input"], item["output"]) for item in st.session_state["memory_log"]]

            # 6.6) Define comparison instructions
            comparison_instr = (
                "Also compute a relevant comparison metric:\n"
                "â€¢ If this is a timeâ€based question, compute prev_metric and next_metric.\n"
                "  For example, â€œsales in March 2025 vs February 2025â€ â†’\n"
                "    main_metric = df[df['Date'].dt.to_period('M') == pd.Period('2025-03', freq='M')]['Total Sales (INR)'].sum()\n"
                "    prev_metric = df[df['Date'].dt.to_period('M') == pd.Period('2025-02', freq='M')]['Total Sales (INR)'].sum()\n"
                "    next_metric = df[df['Date'].dt.to_period('M') == pd.Period('2025-04', freq='M')]['Total Sales (INR)'].sum()\n"
                "â€¢ If this is a ranking question, compute the runnerâ€up (second_metric and second_label).\n"
            )

            # 6.7) Construct the Gemini code prompt
            code_prompt = (
                "You are a Python/Pandas expert. A pandas DataFrame named `df` is loaded in memory, "
                "and the following imports are available:\n"
                "```python\n"
                "import pandas as pd\n"
                "import numpy as np\n"
                "import matplotlib.pyplot as plt\n"
                "import seaborn as sns\n"
                "import scipy.stats as stats\n"
                "```\n\n"
                "Below are the column summaries (name and type):\n"
                f"{summaries}\n\n"
                "Below is a small data sample (Markdown table):\n"
                f"{snippet}\n\n"
                "When given a user question, generate **only valid Python code** that runs against `df`.  \n"
                "- If the question is about trends or timeâ€series, also generate a plot using `plt.subplots()` and store it in `main_plot_fig`.  \n"
                "- Ensure the primary numeric result is stored in `main_metric`.  \n"
                f"{comparison_instr}\n\n"
                "User's question:\n"
                f"\"\"\"{question}\"\"\"\n\n"
                "# Write Python code below (only code, no commentary):"
            )

            # 6.8) Call Gemini to generate the Pandas code
            with st.spinner("ðŸ§  Generating Pandas code..."):
                try:
                    gemini_code = generate_code_from_gemini(code_prompt)
                except ModelAPIError as e:
                    st.error(f"âŒ Error calling Gemini for code generation: {e}")
                    gemini_code = None
                except Exception as e:
                    st.error(f"âš ï¸ Unexpected error calling Gemini: {e}")
                    gemini_code = None

            if gemini_code:
                # 6.9) Display the generated code in an expander
                with st.expander("### ðŸ“ Generated Python Code"):
                    st.code(gemini_code, language="python")

                # 6.10) Execute the code snippet
                with st.spinner("âš™ï¸ Executing generated code..."):
                    try:
                        exec_locals = execute_code_snippet(gemini_code, df, return_all_vars=True)
                    except CodeExecutionError as ce:
                        st.error(f"âŒ Code execution error:\n{ce}")
                        exec_locals = {}

                # 6.11) If exec_locals has content, display metrics & plot
                if exec_locals:
                    # 6.11a) Display computed metrics (excluding any figure)
                    with st.expander("### ðŸ“Š Computed Metrics"):
                        metrics_df = pd.DataFrame(
                            [(k, v) for k, v in exec_locals.items() if k != "main_plot_fig"],
                            columns=["variable", "value"]
                        )
                        st.dataframe(metrics_df, use_container_width=True)

                    # 6.11b) If a figure was generated, show it
                    if "main_plot_fig" in exec_locals:
                        st.markdown("### ðŸ“ˆ Generated Plot")
                        with st.expander("Plot"):
                            st.pyplot(exec_locals["main_plot_fig"])

                    # 6.12) Build a bullet list of metrics for prompting Gemini
                    metrics_text = "\n".join(f"â€¢ {k}: {v}" for k, v in exec_locals.items())

                    # 6.13) Generate a 2â€“3 sentence summary via Gemini
                    summary_prompt = (
                        "You are a concise marketing analyst. The user's question was:\n"
                        f"\"\"\"{question}\"\"\"\n\n"
                        "We computed:\n"
                        f"{metrics_text}\n\n"
                        "In 2â€“3 sentences, provide a brief, actionable summary that highlights the main finding "
                        "and how it compares to the other metrics."
                    )
                    with st.spinner("ðŸ’¬ Generating summary..."):
                        try:
                            summary = generate_response(summary_prompt)
                        except ModelAPIError as e:
                            st.error(f"âŒ Error generating summary: {e}")
                            summary = None
                        except Exception as e:
                            st.error(f"âš ï¸ Unexpected error generating summary: {e}")
                            summary = None

                    if summary:
                        st.markdown("### âœï¸ Summary")
                        st.write(summary)
                    else:
                        st.markdown("### âœï¸ Summary")
                        st.info("Summary not available.")

                    # 6.14) Generate 2â€“4 bullet point strategic recommendation
                    rec_prompt = (
                        "You are a senior marketing strategist or a CEO. Based on the user's question, "
                        "the dataset structure, and the computed metrics, provide a clear recommendation for action. "
                        "This might include campaign adjustments, budget shifts, timing strategies, or deeper analysis directions.\n\n"
                        f"User's question:\n\"\"\"{question}\"\"\"\n\n"
                        f"Computed metrics:\n{metrics_text}\n\n"
                        "Deliver your advice in 2â€“4 concise bullet points with a focus on ROI, customer acquisition, and growth strategy. "
                        "Be direct and actionable like a marketing leader in a business meeting."
                    )
                    with st.spinner("ðŸ“ˆ Generating strategic recommendation..."):
                        try:
                            recommendation = generate_response(rec_prompt)
                        except ModelAPIError as e:
                            st.error(f"âŒ Error generating recommendation: {e}")
                            recommendation = None
                        except Exception as e:
                            st.error(f"âš ï¸ Unexpected error during recommendation: {e}")
                            recommendation = None

                    if recommendation:
                        st.markdown("### ðŸ“ˆ Strategic Recommendation")
                        st.write(recommendation)
                    else:
                        st.markdown("### ðŸ“ˆ Strategic Recommendation")
                        st.info("Recommendation not available.")

                else:
                    # Code ran but returned no variables (likely snippet failed)
                    st.error("âŒ Code executed but returned no variables. Unable to compute metrics.")

                # 6.15) Guarantee summary_text & recommendation_text exist
                summary_text = summary if summary is not None else "Summary not available."
                recommendation_text = (
                    recommendation if recommendation is not None else "Recommendation not available."
                )

                # 6.16) Record conversation in session_state
                st.session_state["last_question"] = question
                st.session_state["memory_log"].append({"input": question, "output": summary_text})
                st.session_state["messages"].append({
                    "question": question,
                    "summary": summary_text,
                    "recommendation": recommendation_text
                })

        # 7) Display chat history if any
        if st.session_state["messages"]:
            st.markdown("### ðŸ’¬ Chat History (Summary + Recommendations)")
            for entry in reversed(st.session_state["messages"]):
                st.markdown(f"**ðŸ§  You asked:** {entry['question']}")
                st.markdown(f"**âœï¸ Summary:** {entry['summary']}")
                st.markdown(f"**ðŸ“ˆ Recommendation:** {entry['recommendation']}")
                st.markdown("---")

    except DataIngestionError as die:
        st.error(f"âŒ Data ingestion error: {die}")
    except Exception as e:
        st.error(f"âš ï¸ Failed to process dataset: {e}")
else:
    st.info("ðŸ‘ˆ Upload a CSV or Excel file to begin.")

# -----------------------------
# 8) Optional: CSS styling for buttons
# -----------------------------
st.markdown(
    """
    <style>
    .stButton>button {
        margin-top: 1rem;
        width: 100%;
        background-color: #444;
        color: white;
    }
    </style>
    """,
    unsafe_allow_html=True
)
